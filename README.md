# VideoCon-Entailment-Evaluation

IT
In questa repository c'è il codice che sto scrivendo per il tirocinio formativo della laurea triennale.
Lo scopo di tale codice è di migliorare il DataSet di VideoCon per l'allenamento e la valutazione di modelli di entailment e generazione testo-video, per fare ciò il dottorando Luca Zanella ha generato dei video integrativi partendo dalle Contrast Captions di VideoCon e dal primo frame del video originale, notando però che spesso influenzare la generazione del video con il primo frame porta ad un risultato peggiore. Il mio compito è quello di investigare i dati per comprendere se si può decidere in manirea automatica, calcolando l'allineamento tra primo frame e le captions (positiva e negativa), quando è utile influenzare la generazione e quando invece la peggiora.
It

EN
In this repository, there is the code I am writing for the internship of the bachelor's degree.
The purpose of this code is to improve the VideoCon DataSet for training and evaluating entailment and generation text-video models. To do this, PhD student Luca Zanella has generated additional videos from VideoCon's Contrast Captions and the first frame of the original video, noting, however, that often influencing the video generation with the first frame leads to a worse result. My task is to investigate the data to understand if it is possible to decide automatically, by calculating the alignment between the first frame and the (positive and negative) captions, when it is useful to influence the generation and when it worsens it.
EN
